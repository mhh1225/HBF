"""
Report Agentä¸»ç±»ã€‚

è¯¥æ¨¡å—ä¸²è”æ¨¡æ¿é€‰æ‹©ã€å¸ƒå±€è®¾è®¡ã€ç« èŠ‚ç”Ÿæˆã€IRè£…è®¢ä¸HTMLæ¸²æŸ“ç­‰
æ‰€æœ‰å­æµç¨‹ï¼Œæ˜¯Report Engineçš„æ€»è°ƒåº¦ä¸­å¿ƒã€‚æ ¸å¿ƒèŒè´£åŒ…æ‹¬ï¼š
1. ç®¡ç†è¾“å…¥æ•°æ®ä¸çŠ¶æ€ï¼Œåè°ƒä¸‰ä¸ªåˆ†æå¼•æ“ã€è®ºå›æ—¥å¿—ä¸æ¨¡æ¿ï¼›
2. æŒ‰èŠ‚ç‚¹é¡ºåºé©±åŠ¨æ¨¡æ¿é€‰æ‹©â†’å¸ƒå±€ç”Ÿæˆâ†’ç¯‡å¹…è§„åˆ’â†’ç« èŠ‚å†™ä½œâ†’è£…è®¢æ¸²æŸ“ï¼›
3. è´Ÿè´£é”™è¯¯å…œåº•ã€æµå¼äº‹ä»¶åˆ†å‘ã€è½ç›˜æ¸…å•ä¸æœ€ç»ˆæˆæœä¿å­˜ã€‚
"""

import json
import os
from copy import deepcopy
from pathlib import Path
from uuid import uuid4
from datetime import datetime
from typing import Optional, Dict, Any, List, Callable, Tuple

from loguru import logger

from .core import (
    ChapterStorage,
    DocumentComposer,
    TemplateSection,
    parse_template_sections,
)
from .ir import IRValidator
from .llms import LLMClient
from .nodes import (
    TemplateSelectionNode,
    ChapterGenerationNode,
    ChapterJsonParseError,
    ChapterContentError,
    DocumentLayoutNode,
    WordBudgetNode,
)
from .renderers import HTMLRenderer
from .state import ReportState
from .utils.config import settings, Settings

# === ã€é©¬æ¬¢æ¬¢æ–°å¢ã€‘å¼•å…¥é“¾æ¥ä¿®å¤ç‰¹å·¥ ===
# è„šæœ¬å­˜ä¸º ReportEngine/ir/link_repair.py
try:
    from .ir.link_repair import LinkRepairAgent
except ImportError:
    # é¿å…å¦‚æœæ²¡æœ‰è¿™ä¸ªæ–‡ä»¶å¯¼è‡´æ•´ä¸ªé¡¹ç›®è·‘ä¸èµ·æ¥
    LinkRepairAgent = None


class StageOutputFormatError(ValueError):
    """é˜¶æ®µæ€§è¾“å‡ºç»“æ„ä¸ç¬¦åˆé¢„æœŸæ—¶æŠ›å‡ºçš„å—æ§å¼‚å¸¸ã€‚"""


class FileCountBaseline:
    """
    æ–‡ä»¶æ•°é‡åŸºå‡†ç®¡ç†å™¨ã€‚

    è¯¥å·¥å…·ç”¨äºï¼š
    - åœ¨ä»»åŠ¡å¯åŠ¨æ—¶è®°å½• Insight/Media/Query ä¸‰ä¸ªå¼•æ“å¯¼å‡ºçš„ Markdown æ•°é‡ï¼›
    - åœ¨åç»­è½®è¯¢ä¸­å¿«é€Ÿåˆ¤æ–­æ˜¯å¦æœ‰æ–°æŠ¥å‘Šè½åœ°ï¼›
    - ä¸º Flask å±‚æä¾›â€œè¾“å…¥æ˜¯å¦å‡†å¤‡å®Œæ¯•â€çš„ä¾æ®ã€‚
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–æ—¶ä¼˜å…ˆå°è¯•è¯»å–æ—¢æœ‰çš„åŸºå‡†å¿«ç…§ã€‚

        è‹¥ `logs/report_baseline.json` ä¸å­˜åœ¨åˆ™ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä»½ç©ºå¿«ç…§ï¼Œ
        ä»¥ä¾¿åç»­ `initialize_baseline` åœ¨é¦–æ¬¡è¿è¡Œæ—¶å†™å…¥çœŸå®åŸºå‡†ã€‚
        """
        self.baseline_file = 'logs/report_baseline.json'
        self.baseline_data = self._load_baseline()
    
    def _load_baseline(self) -> Dict[str, int]:
        """
        åŠ è½½åŸºå‡†æ•°æ®ã€‚

        - å½“å¿«ç…§æ–‡ä»¶å­˜åœ¨æ—¶ç›´æ¥è§£æJSONï¼›
        - æ•è·æ‰€æœ‰åŠ è½½å¼‚å¸¸å¹¶è¿”å›ç©ºå­—å…¸ï¼Œä¿è¯è°ƒç”¨æ–¹é€»è¾‘ç®€æ´ã€‚
        """
        try:
            if os.path.exists(self.baseline_file):
                with open(self.baseline_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.exception(f"åŠ è½½åŸºå‡†æ•°æ®å¤±è´¥: {e}")
        return {}
    
    def _save_baseline(self):
        """
        å°†å½“å‰åŸºå‡†å†™å…¥ç£ç›˜ã€‚

        é‡‡ç”¨ `ensure_ascii=False` + ç¼©è¿›æ ¼å¼ï¼Œæ–¹ä¾¿äººå·¥æŸ¥çœ‹ï¼›
        è‹¥ç›®æ ‡ç›®å½•ç¼ºå¤±åˆ™è‡ªåŠ¨åˆ›å»ºã€‚
        """
        try:
            os.makedirs(os.path.dirname(self.baseline_file), exist_ok=True)
            with open(self.baseline_file, 'w', encoding='utf-8') as f:
                json.dump(self.baseline_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.exception(f"ä¿å­˜åŸºå‡†æ•°æ®å¤±è´¥: {e}")
    
    def initialize_baseline(self, directories: Dict[str, str]) -> Dict[str, int]:
        """
        åˆå§‹åŒ–æ–‡ä»¶æ•°é‡åŸºå‡†ã€‚

        éå†æ¯ä¸ªå¼•æ“ç›®å½•å¹¶ç»Ÿè®¡ `.md` æ–‡ä»¶æ•°é‡ï¼Œå°†ç»“æœæŒä¹…åŒ–ä¸º
        åˆå§‹åŸºå‡†ã€‚åç»­ `check_new_files` ä¼šæ®æ­¤å¯¹æ¯”å¢é‡ã€‚
        """
        current_counts = {}
        
        for engine, directory in directories.items():
            if os.path.exists(directory):
                md_files = [f for f in os.listdir(directory) if f.endswith('.md')]
                current_counts[engine] = len(md_files)
            else:
                current_counts[engine] = 0
        
        # ä¿å­˜åŸºå‡†æ•°æ®
        self.baseline_data = current_counts.copy()
        self._save_baseline()
        
        logger.info(f"æ–‡ä»¶æ•°é‡åŸºå‡†å·²åˆå§‹åŒ–: {current_counts}")
        return current_counts
    
    def check_new_files(self, directories: Dict[str, str]) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶ã€‚

        å¯¹æ¯”å½“å‰ç›®å½•æ–‡ä»¶æ•°ä¸åŸºå‡†ï¼š
        - ç»Ÿè®¡æ–°å¢æ•°é‡ï¼Œå¹¶åˆ¤å®šæ˜¯å¦æ‰€æœ‰å¼•æ“éƒ½å·²å‡†å¤‡å°±ç»ªï¼›
        - è¿”å›è¯¦ç»†è®¡æ•°ã€ç¼ºå¤±åˆ—è¡¨ï¼Œä¾› Web å±‚æç¤ºç»™ç”¨æˆ·ã€‚
        """
        current_counts = {}
        new_files_found = {}
        all_have_new = True
        
        for engine, directory in directories.items():
            if os.path.exists(directory):
                md_files = [f for f in os.listdir(directory) if f.endswith('.md')]
                current_counts[engine] = len(md_files)
                baseline_count = self.baseline_data.get(engine, 0)
                
                if current_counts[engine] > baseline_count:
                    new_files_found[engine] = current_counts[engine] - baseline_count
                else:
                    new_files_found[engine] = 0
                    all_have_new = False
            else:
                current_counts[engine] = 0
                new_files_found[engine] = 0
                all_have_new = False
        
        return {
            'ready': all_have_new,
            'baseline_counts': self.baseline_data,
            'current_counts': current_counts,
            'new_files_found': new_files_found,
            'missing_engines': [engine for engine, count in new_files_found.items() if count == 0]
        }
    
    def get_latest_files(self, directories: Dict[str, str]) -> Dict[str, str]:
        """
        è·å–æ¯ä¸ªç›®å½•çš„æœ€æ–°æ–‡ä»¶ã€‚

        é€šè¿‡ `os.path.getmtime` æ‰¾å‡ºæœ€è¿‘å†™å…¥çš„ Markdownï¼Œ
        ä»¥ç¡®ä¿ç”Ÿæˆæµç¨‹æ°¸è¿œä½¿ç”¨æœ€æ–°ä¸€ç‰ˆä¸‰å¼•æ“æŠ¥å‘Šã€‚
        """
        latest_files = {}
        
        for engine, directory in directories.items():
            if os.path.exists(directory):
                md_files = [f for f in os.listdir(directory) if f.endswith('.md')]
                if md_files:
                    latest_file = max(md_files, key=lambda x: os.path.getmtime(os.path.join(directory, x)))
                    latest_files[engine] = os.path.join(directory, latest_file)
        
        return latest_files


class ReportAgent:
    """
    Report Agentä¸»ç±»ã€‚

    è´Ÿè´£é›†æˆï¼š
    - LLMå®¢æˆ·ç«¯åŠå…¶ä¸Šå±‚å››ä¸ªæ¨ç†èŠ‚ç‚¹ï¼›
    - ç« èŠ‚å­˜å‚¨ã€IRè£…è®¢ã€æ¸²æŸ“å™¨ç­‰äº§å‡ºé“¾è·¯ï¼›
    - çŠ¶æ€ç®¡ç†ã€æ—¥å¿—ã€è¾“å…¥è¾“å‡ºæ ¡éªŒä¸æŒä¹…åŒ–ã€‚
    """
    _CONTENT_SPARSE_MIN_ATTEMPTS = 3
    _CONTENT_SPARSE_WARNING_TEXT = "æœ¬ç« LLMç”Ÿæˆçš„å†…å®¹å­—æ•°å¯èƒ½è¿‡ä½ï¼Œå¿…è¦æ—¶å¯ä»¥å°è¯•é‡æ–°è¿è¡Œç¨‹åºã€‚"
    _STRUCTURAL_RETRY_ATTEMPTS = 2
    
    def __init__(self, config: Optional[Settings] = None):
        """
        åˆå§‹åŒ–Report Agentã€‚
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨åŠ è½½
        
        æ­¥éª¤æ¦‚è§ˆï¼š
            1. è§£æé…ç½®å¹¶æ¥å…¥æ—¥å¿—/LLM/æ¸²æŸ“ç­‰æ ¸å¿ƒç»„ä»¶ï¼›
            2. æ„é€ å››ä¸ªæ¨ç†èŠ‚ç‚¹ï¼ˆæ¨¡æ¿ã€å¸ƒå±€ã€ç¯‡å¹…ã€ç« èŠ‚ï¼‰ï¼›
            3. åˆå§‹åŒ–æ–‡ä»¶åŸºå‡†ä¸ç« èŠ‚è½ç›˜ç›®å½•ï¼›
            4. æ„å»ºå¯åºåˆ—åŒ–çš„çŠ¶æ€å®¹å™¨ï¼Œä¾›å¤–éƒ¨æœåŠ¡æŸ¥è¯¢ã€‚
        """
        # åŠ è½½é…ç½®
        self.config = config or settings
        
        # åˆå§‹åŒ–æ–‡ä»¶åŸºå‡†ç®¡ç†å™¨
        self.file_baseline = FileCountBaseline()
        
        # åˆå§‹åŒ–æ—¥å¿—
        self._setup_logging()
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        self.llm_client = self._initialize_llm()
        self.json_rescue_clients = self._initialize_rescue_llms()
        
        # åˆå§‹åŒ–ç« çº§å­˜å‚¨/æ ¡éªŒ/æ¸²æŸ“ç»„ä»¶
        self.chapter_storage = ChapterStorage(self.config.CHAPTER_OUTPUT_DIR)
        self.document_composer = DocumentComposer()
        self.validator = IRValidator()
        self.renderer = HTMLRenderer()
        
        # åˆå§‹åŒ–èŠ‚ç‚¹
        self._initialize_nodes()
        
        # åˆå§‹åŒ–æ–‡ä»¶æ•°é‡åŸºå‡†
        self._initialize_file_baseline()
        
        # çŠ¶æ€
        self.state = ReportState()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.config.OUTPUT_DIR, exist_ok=True)
        os.makedirs(self.config.DOCUMENT_IR_OUTPUT_DIR, exist_ok=True)
        
        logger.info("Report Agentå·²åˆå§‹åŒ–")
        logger.info(f"ä½¿ç”¨LLM: {self.llm_client.get_model_info()}")
        
    def _setup_logging(self):
        """
        è®¾ç½®æ—¥å¿—ã€‚

        - ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨ï¼›
        - ä½¿ç”¨ç‹¬ç«‹çš„ loguru sink å†™å…¥ Report Engine ä¸“å± log æ–‡ä»¶ï¼Œ
          é¿å…ä¸å…¶ä»–å­ç³»ç»Ÿæ··æ·†ã€‚
        - ã€ä¿®å¤ã€‘é…ç½®å®æ—¶æ—¥å¿—å†™å…¥ï¼Œç¦ç”¨ç¼“å†²ï¼Œç¡®ä¿å‰ç«¯å®æ—¶çœ‹åˆ°æ—¥å¿—
        - ã€ä¿®å¤ã€‘é˜²æ­¢é‡å¤æ·»åŠ handler
        """
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(self.config.LOG_FILE)
        os.makedirs(log_dir, exist_ok=True)

        # ã€ä¿®å¤ã€‘æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ è¿‡è¿™ä¸ªæ–‡ä»¶çš„handlerï¼Œé¿å…é‡å¤
        # loguruä¼šè‡ªåŠ¨å»é‡ï¼Œä½†æ˜¾å¼æ£€æŸ¥æ›´å®‰å…¨
        log_file_path = str(Path(self.config.LOG_FILE).resolve())

        # æ£€æŸ¥ç°æœ‰çš„handlers
        handler_exists = False
        for handler_id, handler_config in logger._core.handlers.items():
            if hasattr(handler_config, 'sink'):
                sink = handler_config.sink
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶sinkä¸”è·¯å¾„ç›¸åŒ
                if hasattr(sink, '_name') and sink._name == log_file_path:
                    handler_exists = True
                    logger.debug(f"æ—¥å¿—handlerå·²å­˜åœ¨ï¼Œè·³è¿‡æ·»åŠ : {log_file_path}")
                    break

        if not handler_exists:
            # ã€ä¿®å¤ã€‘åˆ›å»ºä¸“ç”¨çš„loggerï¼Œé…ç½®å®æ—¶å†™å…¥
            # - enqueue=False: ç¦ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼Œç«‹å³å†™å…¥
            # - buffering=1: è¡Œç¼“å†²ï¼Œæ¯æ¡æ—¥å¿—ç«‹å³åˆ·æ–°åˆ°æ–‡ä»¶
            # - level="DEBUG": è®°å½•æ‰€æœ‰çº§åˆ«çš„æ—¥å¿—
            # - encoding="utf-8": æ˜ç¡®æŒ‡å®šUTF-8ç¼–ç 
            # - mode="a": è¿½åŠ æ¨¡å¼ï¼Œä¿ç•™å†å²æ—¥å¿—
            handler_id = logger.add(
                self.config.LOG_FILE,
                level="DEBUG",
                enqueue=False,      # ç¦ç”¨å¼‚æ­¥é˜Ÿåˆ—ï¼ŒåŒæ­¥å†™å…¥
                buffering=1,        # è¡Œç¼“å†²ï¼Œæ¯è¡Œç«‹å³å†™å…¥
                serialize=False,    # æ™®é€šæ–‡æœ¬æ ¼å¼ï¼Œä¸åºåˆ—åŒ–ä¸ºJSON
                encoding="utf-8",   # æ˜ç¡®UTF-8ç¼–ç 
                mode="a"            # è¿½åŠ æ¨¡å¼
            )
            logger.debug(f"å·²æ·»åŠ æ—¥å¿—handler (ID: {handler_id}): {self.config.LOG_FILE}")

        # ã€ä¿®å¤ã€‘éªŒè¯æ—¥å¿—æ–‡ä»¶å¯å†™
        try:
            with open(self.config.LOG_FILE, 'a', encoding='utf-8') as f:
                f.write('')  # å°è¯•å†™å…¥ç©ºå­—ç¬¦ä¸²éªŒè¯æƒé™
                f.flush()    # ç«‹å³åˆ·æ–°
        except Exception as e:
            logger.error(f"æ—¥å¿—æ–‡ä»¶æ— æ³•å†™å…¥: {self.config.LOG_FILE}, é”™è¯¯: {e}")
            raise
        
    def _initialize_file_baseline(self):
        """
        åˆå§‹åŒ–æ–‡ä»¶æ•°é‡åŸºå‡†ã€‚

        å°† Insight/Media/Query ä¸‰ä¸ªç›®å½•ä¼ å…¥ `FileCountBaseline`ï¼Œ
        ç”Ÿæˆä¸€æ¬¡æ€§çš„å‚è€ƒå€¼ï¼Œä¹‹åæŒ‰å¢é‡åˆ¤æ–­ä¸‰å¼•æ“æ˜¯å¦äº§å‡ºæ–°æŠ¥å‘Šã€‚
        """
        directories = {
            'insight': 'insight_engine_streamlit_reports',
            'media': 'media_engine_streamlit_reports',
            'query': 'query_engine_streamlit_reports'
        }
        self.file_baseline.initialize_baseline(directories)
    
    def _initialize_llm(self) -> LLMClient:
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ã€‚

        åˆ©ç”¨é…ç½®ä¸­çš„ API Key / æ¨¡å‹ / Base URL æ„å»ºç»Ÿä¸€çš„
        `LLMClient` å®ä¾‹ï¼Œä¸ºæ‰€æœ‰èŠ‚ç‚¹æä¾›å¤ç”¨çš„æ¨ç†å…¥å£ã€‚
        """
        return LLMClient(
            api_key=self.config.REPORT_ENGINE_API_KEY,
            model_name=self.config.REPORT_ENGINE_MODEL_NAME,
            base_url=self.config.REPORT_ENGINE_BASE_URL,
        )

    def _initialize_rescue_llms(self) -> List[Tuple[str, LLMClient]]:
        """
        åˆå§‹åŒ–è·¨å¼•æ“ç« èŠ‚ä¿®å¤æ‰€éœ€çš„LLMå®¢æˆ·ç«¯åˆ—è¡¨ã€‚

        é¡ºåºéµå¾ªâ€œReport â†’ Forum â†’ Insight â†’ Mediaâ€ï¼Œç¼ºå¤±é…ç½®ä¼šè¢«è‡ªåŠ¨è·³è¿‡ã€‚
        """
        clients: List[Tuple[str, LLMClient]] = []
        if self.llm_client:
            clients.append(("report_engine", self.llm_client))
        fallback_specs = [
            (
                "forum_engine",
                self.config.FORUM_HOST_API_KEY,
                self.config.FORUM_HOST_MODEL_NAME,
                self.config.FORUM_HOST_BASE_URL,
            ),
            (
                "insight_engine",
                self.config.INSIGHT_ENGINE_API_KEY,
                self.config.INSIGHT_ENGINE_MODEL_NAME,
                self.config.INSIGHT_ENGINE_BASE_URL,
            ),
            (
                "media_engine",
                self.config.MEDIA_ENGINE_API_KEY,
                self.config.MEDIA_ENGINE_MODEL_NAME,
                self.config.MEDIA_ENGINE_BASE_URL,
            ),
        ]
        for label, api_key, model_name, base_url in fallback_specs:
            if not api_key or not model_name:
                continue
            try:
                client = LLMClient(api_key=api_key, model_name=model_name, base_url=base_url)
            except Exception as exc:
                logger.warning(f"{label} LLMåˆå§‹åŒ–å¤±è´¥ï¼Œè·³è¿‡è¯¥ä¿®å¤é€šé“: {exc}")
                continue
            clients.append((label, client))
        return clients
    
    def _initialize_nodes(self):
        """
        åˆå§‹åŒ–å¤„ç†èŠ‚ç‚¹ã€‚

        é¡ºåºå®ä¾‹åŒ–æ¨¡æ¿é€‰æ‹©ã€æ–‡æ¡£å¸ƒå±€ã€ç¯‡å¹…è§„åˆ’ã€ç« èŠ‚ç”Ÿæˆå››ä¸ªèŠ‚ç‚¹ï¼Œ
        å…¶ä¸­ç« èŠ‚èŠ‚ç‚¹é¢å¤–ä¾èµ– IR æ ¡éªŒå™¨ä¸ç« èŠ‚å­˜å‚¨å™¨ã€‚
        """
        self.template_selection_node = TemplateSelectionNode(
            self.llm_client,
            self.config.TEMPLATE_DIR
        )
        self.document_layout_node = DocumentLayoutNode(self.llm_client)
        self.word_budget_node = WordBudgetNode(self.llm_client)
        self.chapter_generation_node = ChapterGenerationNode(
            self.llm_client,
            self.validator,
            self.chapter_storage,
            fallback_llm_clients=self.json_rescue_clients,
            error_log_dir=self.config.JSON_ERROR_LOG_DIR,
        )
    
    def generate_report(self, query: str, reports: List[Any], forum_logs: str = "",
                        custom_template: str = "", save_report: bool = True,
                        stream_handler: Optional[Callable[[str, Dict[str, Any]], None]] = None) -> str:
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Šï¼ˆç« èŠ‚JSON â†’ IR â†’ HTMLï¼‰ã€‚

        ä¸»è¦é˜¶æ®µï¼š
            1. å½’ä¸€åŒ–ä¸‰å¼•æ“æŠ¥å‘Š + è®ºå›æ—¥å¿—ï¼Œå¹¶è¾“å‡ºæµå¼äº‹ä»¶ï¼›
            2. æ¨¡æ¿é€‰æ‹© â†’ æ¨¡æ¿åˆ‡ç‰‡ â†’ æ–‡æ¡£å¸ƒå±€ â†’ ç¯‡å¹…è§„åˆ’ï¼›
            3. ç»“åˆç¯‡å¹…ç›®æ ‡é€ç« è°ƒç”¨LLMï¼Œé‡åˆ°è§£æé”™è¯¯ä¼šè‡ªåŠ¨é‡è¯•ï¼›
            4. å°†ç« èŠ‚è£…è®¢æˆDocument IRï¼Œå†äº¤ç»™HTMLæ¸²æŸ“å™¨ç”Ÿæˆæˆå“ï¼›
            5. å¯é€‰åœ°å°†HTML/IR/çŠ¶æ€è½ç›˜ï¼Œå¹¶å‘å¤–ç•Œå›ä¼ è·¯å¾„ä¿¡æ¯ã€‚

        å‚æ•°:
            query: æœ€ç»ˆè¦ç”Ÿæˆçš„æŠ¥å‘Šä¸»é¢˜æˆ–æé—®è¯­å¥ã€‚
            reports: æ¥è‡ª Query/Media/Insight ç­‰åˆ†æå¼•æ“çš„åŸå§‹è¾“å‡ºï¼Œå…è®¸ä¼ å…¥å­—ç¬¦ä¸²æˆ–æ›´å¤æ‚çš„å¯¹è±¡ã€‚
            forum_logs: è®ºå›/ååŒè®°å½•ï¼Œä¾›LLMç†è§£å¤šäººè®¨è®ºä¸Šä¸‹æ–‡ã€‚
            custom_template: ç”¨æˆ·æŒ‡å®šçš„Markdownæ¨¡æ¿ï¼Œå¦‚ä¸ºç©ºåˆ™äº¤ç”±æ¨¡æ¿èŠ‚ç‚¹è‡ªåŠ¨æŒ‘é€‰ã€‚
            save_report: æ˜¯å¦åœ¨ç”Ÿæˆåè‡ªåŠ¨å°†HTMLã€IRä¸çŠ¶æ€å†™å…¥ç£ç›˜ã€‚
            stream_handler: å¯é€‰çš„æµå¼äº‹ä»¶å›è°ƒï¼Œæ¥æ”¶é˜¶æ®µæ ‡ç­¾ä¸payloadï¼Œç”¨äºUIå®æ—¶å±•ç¤ºã€‚

        è¿”å›:
            dict: åŒ…å« `html_content` ä»¥åŠHTML/IR/çŠ¶æ€æ–‡ä»¶è·¯å¾„çš„å­—å…¸ï¼›è‹¥ `save_report=False` åˆ™ä»…è¿”å›HTMLå­—ç¬¦ä¸²ã€‚

        å¼‚å¸¸:
            Exception: ä»»ä¸€å­èŠ‚ç‚¹æˆ–æ¸²æŸ“é˜¶æ®µå¤±è´¥æ—¶æŠ›å‡ºï¼Œå¤–å±‚è°ƒç”¨æ–¹è´Ÿè´£å…œåº•ã€‚
        """
        start_time = datetime.now()
        report_id = f"report-{uuid4().hex[:8]}"
        self.state.task_id = report_id
        self.state.query = query
        self.state.metadata.query = query
        self.state.mark_processing()

        normalized_reports = self._normalize_reports(reports)

        def emit(event_type: str, payload: Dict[str, Any]):
            """é¢å‘Report Engineæµé€šé“çš„äº‹ä»¶åˆ†å‘å™¨ï¼Œä¿è¯é”™è¯¯ä¸å¤–æ³„ã€‚"""
            if not stream_handler:
                return
            try:
                stream_handler(event_type, payload)
            except Exception as callback_error:  # pragma: no cover - ä»…è®°å½•
                logger.warning(f"æµå¼äº‹ä»¶å›è°ƒå¤±è´¥: {callback_error}")

        logger.info(f"å¼€å§‹ç”ŸæˆæŠ¥å‘Š {report_id}: {query}")
        logger.info(f"è¾“å…¥æ•°æ® - æŠ¥å‘Šæ•°é‡: {len(reports)}, è®ºå›æ—¥å¿—é•¿åº¦: {len(str(forum_logs))}")
        emit('stage', {'stage': 'agent_start', 'report_id': report_id, 'query': query})

        try:
            template_result = self._select_template(query, reports, forum_logs, custom_template)
            template_result = self._ensure_mapping(
                template_result,
                "æ¨¡æ¿é€‰æ‹©ç»“æœ",
                expected_keys=["template_name", "template_content"],
            )
            self.state.metadata.template_used = template_result.get('template_name', '')
            emit('stage', {
                'stage': 'template_selected',
                'template': template_result.get('template_name'),
                'reason': template_result.get('selection_reason')
            })
            emit('progress', {'progress': 10, 'message': 'æ¨¡æ¿é€‰æ‹©å®Œæˆ'})
            sections = self._slice_template(template_result.get('template_content', ''))
            if not sections:
                raise ValueError("æ¨¡æ¿æ— æ³•è§£æå‡ºç« èŠ‚ï¼Œè¯·æ£€æŸ¥æ¨¡æ¿å†…å®¹ã€‚")
            emit('stage', {'stage': 'template_sliced', 'section_count': len(sections)})

            template_text = template_result.get('template_content', '')
            template_overview = self._build_template_overview(template_text, sections)
            # åŸºäºæ¨¡æ¿éª¨æ¶+ä¸‰å¼•æ“å†…å®¹è®¾è®¡å…¨å±€æ ‡é¢˜ã€ç›®å½•ä¸è§†è§‰ä¸»é¢˜
            layout_design = self._run_stage_with_retry(
                "æ–‡æ¡£è®¾è®¡",
                lambda: self.document_layout_node.run(
                    sections,
                    template_text,
                    normalized_reports,
                    forum_logs,
                    query,
                    template_overview,
                ),
                expected_keys=["title", "hero", "toc", "tocPlan"],
            )
            emit('stage', {
                'stage': 'layout_designed',
                'title': layout_design.get('title'),
                'toc': layout_design.get('tocTitle')
            })
            emit('progress', {'progress': 15, 'message': 'æ–‡æ¡£æ ‡é¢˜/ç›®å½•è®¾è®¡å®Œæˆ'})
            # ä½¿ç”¨åˆšç”Ÿæˆçš„è®¾è®¡ç¨¿å¯¹å…¨ä¹¦è¿›è¡Œç¯‡å¹…è§„åˆ’ï¼Œçº¦æŸå„ç« å­—æ•°ä¸é‡ç‚¹
            word_plan = self._run_stage_with_retry(
                "ç« èŠ‚ç¯‡å¹…è§„åˆ’",
                lambda: self.word_budget_node.run(
                    sections,
                    layout_design,
                    normalized_reports,
                    forum_logs,
                    query,
                    template_overview,
                ),
                expected_keys=["chapters", "totalWords", "globalGuidelines"],
                postprocess=self._normalize_word_plan,
            )
            emit('stage', {
                'stage': 'word_plan_ready',
                'chapter_targets': len(word_plan.get('chapters', []))
            })
            emit('progress', {'progress': 20, 'message': 'ç« èŠ‚å­—æ•°è§„åˆ’å·²ç”Ÿæˆ'})
            # è®°å½•æ¯ä¸ªç« èŠ‚çš„ç›®æ ‡å­—æ•°/å¼ºè°ƒç‚¹ï¼Œåç»­ä¼ ç»™ç« èŠ‚LLM
            chapter_targets = {
                entry.get("chapterId"): entry
                for entry in word_plan.get("chapters", [])
                if entry.get("chapterId")
            }

            generation_context = self._build_generation_context(
                query,
                normalized_reports,
                forum_logs,
                template_result,
                layout_design,
                chapter_targets,
                word_plan,
                template_overview,
            )
            # IR/æ¸²æŸ“éœ€è¦çš„å…¨å±€å…ƒæ•°æ®ï¼Œå¸¦ä¸Šè®¾è®¡ç¨¿ç»™å‡ºçš„æ ‡é¢˜/ä¸»é¢˜/ç›®å½•/ç¯‡å¹…ä¿¡æ¯
            manifest_meta = {
                "query": query,
                "title": layout_design.get("title") or (f"{query} - èˆ†æƒ…æ´å¯ŸæŠ¥å‘Š" if query else template_result.get("template_name")),
                "subtitle": layout_design.get("subtitle"),
                "tagline": layout_design.get("tagline"),
                "templateName": template_result.get("template_name"),
                "selectionReason": template_result.get("selection_reason"),
                "themeTokens": generation_context.get("theme_tokens", {}),
                "toc": {
                    "depth": 3,
                    "autoNumbering": True,
                    "title": layout_design.get("tocTitle") or "ç›®å½•",
                },
                "hero": layout_design.get("hero"),
                "layoutNotes": layout_design.get("layoutNotes"),
                "wordPlan": {
                    "totalWords": word_plan.get("totalWords"),
                    "globalGuidelines": word_plan.get("globalGuidelines"),
                },
                "templateOverview": template_overview,
            }
            if layout_design.get("themeTokens"):
                manifest_meta["themeTokens"] = layout_design["themeTokens"]
            if layout_design.get("tocPlan"):
                manifest_meta["toc"]["customEntries"] = layout_design["tocPlan"]
            # åˆå§‹åŒ–ç« èŠ‚è¾“å‡ºç›®å½•å¹¶å†™å…¥manifestï¼Œæ–¹ä¾¿æµå¼å­˜ç›˜
            run_dir = self.chapter_storage.start_session(report_id, manifest_meta)
            self._persist_planning_artifacts(run_dir, layout_design, word_plan, template_overview)
            emit('stage', {'stage': 'storage_ready', 'run_dir': str(run_dir)})

            chapters = []
            chapter_max_attempts = max(
                self._CONTENT_SPARSE_MIN_ATTEMPTS, self.config.CHAPTER_JSON_MAX_ATTEMPTS
            )
            total_chapters = len(sections)  # æ€»ç« èŠ‚æ•°
            completed_chapters = 0  # å·²å®Œæˆç« èŠ‚æ•°

            for section in sections:
                logger.info(f"ç”Ÿæˆç« èŠ‚: {section.title}")
                emit('chapter_status', {
                    'chapterId': section.chapter_id,
                    'title': section.title,
                    'status': 'running'
                })
                # ç« èŠ‚æµå¼å›è°ƒï¼šæŠŠLLMè¿”å›çš„deltaé€ä¼ ç»™SSEï¼Œä¾¿äºå‰ç«¯å®æ—¶æ¸²æŸ“
                def chunk_callback(delta: str, meta: Dict[str, Any], section_ref: TemplateSection = section):
                    """
                    ç« èŠ‚å†…å®¹æµå¼å›è°ƒã€‚

                    Args:
                        delta: LLMæœ€æ–°è¾“å‡ºçš„å¢é‡æ–‡æœ¬ã€‚
                        meta: èŠ‚ç‚¹å›ä¼ çš„ç« èŠ‚å…ƒæ•°æ®ï¼Œå…œåº•æ—¶ä½¿ç”¨ã€‚
                        section_ref: é»˜è®¤æŒ‡å‘å½“å‰ç« èŠ‚ï¼Œä¿è¯åœ¨ç¼ºå¤±å…ƒä¿¡æ¯æ—¶ä¹Ÿèƒ½å®šä½ã€‚
                    """
                    emit('chapter_chunk', {
                        'chapterId': meta.get('chapterId') or section_ref.chapter_id,
                        'title': meta.get('title') or section_ref.title,
                        'delta': delta
                    })

                chapter_payload: Dict[str, Any] | None = None
                attempt = 1
                best_sparse_candidate: Dict[str, Any] | None = None
                best_sparse_score = -1
                fallback_used = False
                while attempt <= chapter_max_attempts:
                    try:
                        chapter_payload = self.chapter_generation_node.run(
                            section,
                            generation_context,
                            run_dir,
                            stream_callback=chunk_callback
                        )
                        break
                    except (ChapterJsonParseError, ChapterContentError) as structured_error:
                        error_kind = (
                            "content_sparse" if isinstance(structured_error, ChapterContentError) else "json_parse"
                        )
                        readable_label = "å†…å®¹å¯†åº¦å¼‚å¸¸" if error_kind == "content_sparse" else "JSONè§£æå¤±è´¥"
                        if isinstance(structured_error, ChapterContentError):
                            candidate = getattr(structured_error, "chapter_payload", None)
                            candidate_score = getattr(structured_error, "body_characters", 0) or 0
                            if isinstance(candidate, dict) and candidate_score >= 0:
                                if candidate_score > best_sparse_score:
                                    best_sparse_candidate = deepcopy(candidate)
                                    best_sparse_score = candidate_score
                        will_fallback = (
                            isinstance(structured_error, ChapterContentError)
                            and attempt >= chapter_max_attempts
                            and attempt >= self._CONTENT_SPARSE_MIN_ATTEMPTS
                            and best_sparse_candidate is not None
                        )
                        logger.warning(
                            "ç« èŠ‚ {title} {label}ï¼ˆç¬¬ {attempt}/{total} æ¬¡å°è¯•ï¼‰: {error}",
                            title=section.title,
                            label=readable_label,
                            attempt=attempt,
                            total=chapter_max_attempts,
                            error=structured_error,
                        )
                        status_value = 'retrying' if attempt < chapter_max_attempts or will_fallback else 'error'
                        status_payload = {
                            'chapterId': section.chapter_id,
                            'title': section.title,
                            'status': status_value,
                            'attempt': attempt,
                            'error': str(structured_error),
                            'reason': error_kind,
                        }
                        if will_fallback:
                            status_payload['warning'] = 'content_sparse_fallback_pending'
                        emit('chapter_status', status_payload)
                        if will_fallback:
                            logger.warning(
                                "ç« èŠ‚ {title} è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ï¼Œä¿ç•™å­—æ•°æœ€å¤šï¼ˆçº¦ {score} å­—ï¼‰çš„ç‰ˆæœ¬ä½œä¸ºå…œåº•è¾“å‡º",
                                title=section.title,
                                score=best_sparse_score,
                            )
                            chapter_payload = self._finalize_sparse_chapter(best_sparse_candidate)
                            fallback_used = True
                            break
                        if attempt >= chapter_max_attempts:
                            raise
                        attempt += 1
                        continue
                    except Exception as chapter_error:
                        if not self._should_retry_inappropriate_content_error(chapter_error):
                            raise
                        logger.warning(
                            "ç« èŠ‚ {title} è§¦å‘å†…å®¹å®‰å…¨é™åˆ¶ï¼ˆç¬¬ {attempt}/{total} æ¬¡å°è¯•ï¼‰ï¼Œå‡†å¤‡é‡æ–°ç”Ÿæˆ: {error}",
                            title=section.title,
                            attempt=attempt,
                            total=chapter_max_attempts,
                            error=chapter_error,
                        )
                        emit('chapter_status', {
                            'chapterId': section.chapter_id,
                            'title': section.title,
                            'status': 'retrying' if attempt < chapter_max_attempts else 'error',
                            'attempt': attempt,
                            'error': str(chapter_error),
                            'reason': 'content_filter'
                        })
                        if attempt >= chapter_max_attempts:
                            raise
                        attempt += 1
                        continue
                if chapter_payload is None:
                    raise ChapterJsonParseError(
                        f"{section.title} ç« èŠ‚JSONåœ¨ {chapter_max_attempts} æ¬¡å°è¯•åä»æ— æ³•è§£æ"
                    )
                chapters.append(chapter_payload)
                completed_chapters += 1  # æ›´æ–°å·²å®Œæˆç« èŠ‚æ•°
                # è®¡ç®—å½“å‰è¿›åº¦ï¼š20% + 80% * (å·²å®Œæˆç« èŠ‚æ•° / æ€»ç« èŠ‚æ•°)ï¼Œå››èˆäº”å…¥
                chapter_progress = 20 + round(80 * completed_chapters / total_chapters)
                emit('progress', {
                    'progress': chapter_progress,
                    'message': f'ç« èŠ‚ {completed_chapters}/{total_chapters} å·²å®Œæˆ'
                })
                completion_status = {
                    'chapterId': section.chapter_id,
                    'title': section.title,
                    'status': 'completed',
                    'attempt': attempt,
                }
                if fallback_used:
                    completion_status['warning'] = 'content_sparse_fallback'
                    completion_status['warningMessage'] = self._CONTENT_SPARSE_WARNING_TEXT
                emit('chapter_status', completion_status)

            document_ir = self.document_composer.build_document(
                report_id,
                manifest_meta,
                chapters
            )
            emit('stage', {'stage': 'chapters_compiled', 'chapter_count': len(chapters)})
            # ========================================================
            # ã€æ–°å¢ã€‘å¯åŠ¨é“¾æ¥è‡ªæ„ˆæµç¨‹ (Link Repair Loop)
            # ========================================================
            if LinkRepairAgent:
                try:
                    logger.info("ğŸ”§ å¯åŠ¨é“¾æ¥ä¿®å¤ç‰¹å·¥ï¼Œæ­£åœ¨æ£€æµ‹å¹¶æ›¿æ¢å¤±æ•ˆé“¾æ¥...")
                    emit('stage', {'stage': 'link_repairing', 'message': 'æ­£åœ¨éªŒè¯å¹¶ä¿®å¤æŠ¥å‘Šé“¾æ¥...'})

                    repair_agent = LinkRepairAgent()
                    # ç›´æ¥ä¿®æ”¹ document_ir å¯¹è±¡
                    document_ir = repair_agent.repair_process(document_ir)

                    logger.info("âœ… é“¾æ¥ä¿®å¤å®Œæˆ")
                except Exception as e:
                    logger.warning(f"âš ï¸ é“¾æ¥ä¿®å¤è¿‡ç¨‹å‡ºç°å¼‚å¸¸ï¼ˆä¸å½±å“æŠ¥å‘Šç”Ÿæˆï¼‰: {e}")
            # ========================================================
            html_report = self.renderer.render(document_ir)
            emit('stage', {'stage': 'html_rendered', 'html_length': len(html_report)})

            self.state.html_content = html_report
            self.state.mark_completed()

            saved_files = {}
            if save_report:
                saved_files = self._save_report(html_report, document_ir, report_id)
                emit('stage', {'stage': 'report_saved', 'files': saved_files})

            generation_time = (datetime.now() - start_time).total_seconds()
            self.state.metadata.generation_time = generation_time
            logger.info(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {generation_time:.2f} ç§’")
            emit('metrics', {'generation_seconds': generation_time})
            return {
                'html_content': html_report,
                'report_id': report_id,
                **saved_files
            }

        except Exception as e:
            self.state.mark_failed(str(e))
            logger.exception(f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            emit('error', {'stage': 'agent_failed', 'message': str(e)})
            raise
    
    def _select_template(self, query: str, reports: List[Any], forum_logs: str, custom_template: str):
        """
        é€‰æ‹©æŠ¥å‘Šæ¨¡æ¿ã€‚

        ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡æ¿ï¼›å¦åˆ™å°†æŸ¥è¯¢ã€ä¸‰å¼•æ“æŠ¥å‘Šä¸è®ºå›æ—¥å¿—
        ä½œä¸ºä¸Šä¸‹æ–‡äº¤ç»™ TemplateSelectionNodeï¼Œç”± LLM è¿”å›æœ€å¥‘åˆçš„
        æ¨¡æ¿åç§°ã€å†…å®¹åŠç†ç”±ï¼Œå¹¶è‡ªåŠ¨è®°å½•åœ¨çŠ¶æ€ä¸­ã€‚

        å‚æ•°:
            query: æŠ¥å‘Šä¸»é¢˜ï¼Œç”¨äºæç¤ºè¯èšç„¦è¡Œä¸š/äº‹ä»¶ã€‚
            reports: å¤šæ¥æºæŠ¥å‘ŠåŸæ–‡ï¼Œå¸®åŠ©LLMåˆ¤æ–­ç»“æ„å¤æ‚åº¦ã€‚
            forum_logs: å¯¹åº”è®ºå›æˆ–åä½œè®¨è®ºçš„æ–‡æœ¬ï¼Œç”¨äºè¡¥å……èƒŒæ™¯ã€‚
            custom_template: CLI/å‰ç«¯ä¼ å…¥çš„è‡ªå®šä¹‰Markdownæ¨¡æ¿ï¼Œéç©ºæ—¶ç›´æ¥é‡‡ç”¨ã€‚

        è¿”å›:
            dict: åŒ…å« `template_name`ã€`template_content` ä¸ `selection_reason` çš„ç»“æ„åŒ–ç»“æœï¼Œä¾›åç»­èŠ‚ç‚¹æ¶ˆè´¹ã€‚
        """
        logger.info("é€‰æ‹©æŠ¥å‘Šæ¨¡æ¿...")
        
        # å¦‚æœç”¨æˆ·æä¾›äº†è‡ªå®šä¹‰æ¨¡æ¿ï¼Œç›´æ¥ä½¿ç”¨
        if custom_template:
            logger.info("ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰æ¨¡æ¿")
            return {
                'template_name': 'custom',
                'template_content': custom_template,
                'selection_reason': 'ç”¨æˆ·æŒ‡å®šçš„è‡ªå®šä¹‰æ¨¡æ¿'
            }
        
        template_input = {
            'query': query,
            'reports': reports,
            'forum_logs': forum_logs
        }
        
        try:
            template_result = self.template_selection_node.run(template_input)
            
            # æ›´æ–°çŠ¶æ€
            self.state.metadata.template_used = template_result['template_name']
            
            logger.info(f"é€‰æ‹©æ¨¡æ¿: {template_result['template_name']}")
            logger.info(f"é€‰æ‹©ç†ç”±: {template_result['selection_reason']}")
            
            return template_result
        except Exception as e:
            logger.error(f"æ¨¡æ¿é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {str(e)}")
            # ç›´æ¥ä½¿ç”¨å¤‡ç”¨æ¨¡æ¿
            fallback_template = {
                'template_name': 'ç¤¾ä¼šå…¬å…±çƒ­ç‚¹äº‹ä»¶åˆ†ææŠ¥å‘Šæ¨¡æ¿',
                'template_content': self._get_fallback_template_content(),
                'selection_reason': 'æ¨¡æ¿é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç¤¾ä¼šçƒ­ç‚¹äº‹ä»¶åˆ†ææ¨¡æ¿'
            }
            self.state.metadata.template_used = fallback_template['template_name']
            return fallback_template
    
    def _slice_template(self, template_markdown: str) -> List[TemplateSection]:
        """
        å°†æ¨¡æ¿åˆ‡æˆç« èŠ‚åˆ—è¡¨ï¼Œè‹¥ä¸ºç©ºåˆ™æä¾›fallbackã€‚

        å§”æ‰˜ `parse_template_sections` å°†Markdownæ ‡é¢˜/ç¼–å·è§£æä¸º
        `TemplateSection` åˆ—è¡¨ï¼Œç¡®ä¿åç»­ç« èŠ‚ç”Ÿæˆæœ‰ç¨³å®šçš„ç« èŠ‚IDã€‚
        å½“æ¨¡æ¿æ ¼å¼å¼‚å¸¸æ—¶ï¼Œä¼šå›é€€åˆ°å†…ç½®çš„ç®€å•éª¨æ¶é¿å…å´©æºƒã€‚

        å‚æ•°:
            template_markdown: å®Œæ•´çš„æ¨¡æ¿Markdownæ–‡æœ¬ã€‚

        è¿”å›:
            list[TemplateSection]: è§£æåçš„ç« èŠ‚åºåˆ—ï¼›å¦‚è§£æå¤±è´¥åˆ™è¿”å›å•ç« å…œåº•ç»“æ„ã€‚
        """
        sections = parse_template_sections(template_markdown)
        if sections:
            return sections
        logger.warning("æ¨¡æ¿æœªè§£æå‡ºç« èŠ‚ï¼Œä½¿ç”¨é»˜è®¤ç« èŠ‚éª¨æ¶")
        fallback = TemplateSection(
            title="1.0 ç»¼åˆåˆ†æ",
            slug="section-1-0",
            order=10,
            depth=1,
            raw_title="1.0 ç»¼åˆåˆ†æ",
            number="1.0",
            chapter_id="S1",
            outline=["1.1 æ‘˜è¦", "1.2 æ•°æ®äº®ç‚¹", "1.3 é£é™©æç¤º"],
        )
        return [fallback]

    def _build_generation_context(
        self,
        query: str,
        reports: Dict[str, str],
        forum_logs: str,
        template_result: Dict[str, Any],
        layout_design: Dict[str, Any],
        chapter_directives: Dict[str, Any],
        word_plan: Dict[str, Any],
        template_overview: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        æ„é€ ç« èŠ‚ç”Ÿæˆæ‰€éœ€çš„å…±äº«ä¸Šä¸‹æ–‡ã€‚

        å°†æ¨¡æ¿åç§°ã€å¸ƒå±€è®¾è®¡ã€ä¸»é¢˜é…è‰²ã€ç¯‡å¹…è§„åˆ’ã€è®ºå›æ—¥å¿—ç­‰
        ä¸€æ¬¡æ€§æ•´åˆä¸º `generation_context`ï¼Œåç»­æ¯ç« è°ƒç”¨ LLM æ—¶
        ç›´æ¥å¤ç”¨ï¼Œç¡®ä¿æ‰€æœ‰ç« èŠ‚å…±äº«ä¸€è‡´çš„è¯­è°ƒå’Œè§†è§‰çº¦æŸã€‚

        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢è¯ã€‚
            reports: å½’ä¸€åŒ–åçš„ query/media/insight æŠ¥å‘Šæ˜ å°„ã€‚
            forum_logs: ä¸‰å¼•æ“è®¨è®ºè®°å½•ã€‚
            template_result: æ¨¡æ¿èŠ‚ç‚¹è¿”å›çš„æ¨¡æ¿å…ƒä¿¡æ¯ã€‚
            layout_design: æ–‡æ¡£å¸ƒå±€èŠ‚ç‚¹äº§å‡ºçš„æ ‡é¢˜/ç›®å½•/ä¸»é¢˜è®¾è®¡ã€‚
            chapter_directives: å­—æ•°è§„åˆ’èŠ‚ç‚¹è¿”å›çš„ç« èŠ‚æŒ‡ä»¤æ˜ å°„ã€‚
            word_plan: ç¯‡å¹…è§„åˆ’åŸå§‹ç»“æœï¼ŒåŒ…å«å…¨å±€å­—æ•°çº¦æŸã€‚
            template_overview: æ¨¡æ¿åˆ‡ç‰‡æç‚¼çš„ç« èŠ‚éª¨æ¶æ‘˜è¦ã€‚

        è¿”å›:
            dict: LLMç« èŠ‚ç”Ÿæˆæ‰€éœ€çš„å…¨é›†ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«ä¸»é¢˜è‰²ã€å¸ƒå±€ã€çº¦æŸç­‰é”®ã€‚
        """
        # ä¼˜å…ˆä½¿ç”¨è®¾è®¡ç¨¿å®šåˆ¶çš„ä¸»é¢˜è‰²ï¼Œå¦åˆ™é€€å›é»˜è®¤ä¸»é¢˜
        theme_tokens = (
            layout_design.get("themeTokens")
            if layout_design else None
        ) or self._default_theme_tokens()

        return {
            "query": query,
            "template_name": template_result.get("template_name"),
            "reports": reports,
            "forum_logs": self._stringify(forum_logs),
            "theme_tokens": theme_tokens,
            "style_directives": {
                "tone": "analytical",
                "audience": "executive",
                "language": "zh-CN",
            },
            "data_bundles": [],
            "max_tokens": min(self.config.MAX_CONTENT_LENGTH, 6000),
            "layout": layout_design or {},
            "template_overview": template_overview or {},
            "chapter_directives": chapter_directives or {},
            "word_plan": word_plan or {},
        }

    def _normalize_reports(self, reports: List[Any]) -> Dict[str, str]:
        """
        å°†ä¸åŒæ¥æºçš„æŠ¥å‘Šç»Ÿä¸€è½¬ä¸ºå­—ç¬¦ä¸²ã€‚

        çº¦å®šé¡ºåºä¸º Query/Media/Insightï¼Œå¼•æ“æä¾›çš„å¯¹è±¡å¯èƒ½æ˜¯
        å­—å…¸æˆ–è‡ªå®šä¹‰ç±»å‹ï¼Œå› æ­¤ç»Ÿä¸€èµ° `_stringify` åšå®¹é”™ã€‚

        å‚æ•°:
            reports: ä»»æ„ç±»å‹çš„æŠ¥å‘Šåˆ—è¡¨ï¼Œå…è®¸ç¼ºå¤±æˆ–é¡ºåºæ··ä¹±ã€‚

        è¿”å›:
            dict: åŒ…å« `query_engine`/`media_engine`/`insight_engine` ä¸‰ä¸ªå­—ç¬¦ä¸²å­—æ®µçš„æ˜ å°„ã€‚
        """
        keys = ["query_engine", "media_engine", "insight_engine"]
        normalized: Dict[str, str] = {}
        for idx, key in enumerate(keys):
            value = reports[idx] if idx < len(reports) else ""
            normalized[key] = self._stringify(value)
        return normalized

    def _should_retry_inappropriate_content_error(self, error: Exception) -> bool:
        """
        åˆ¤æ–­LLMå¼‚å¸¸æ˜¯å¦ç”±å†…å®¹å®‰å…¨/ä¸å½“å†…å®¹å¯¼è‡´ã€‚

        å½“æ£€æµ‹åˆ°ä¾›åº”å•†è¿”å›çš„é”™è¯¯åŒ…å«ç‰¹å®šå…³é”®è¯æ—¶ï¼Œå…è®¸ç« èŠ‚ç”Ÿæˆ
        é‡æ–°å°è¯•ï¼Œä»¥ä¾¿ç»•è¿‡å¶å‘çš„å†…å®¹å®¡æŸ¥è§¦å‘ã€‚

        å‚æ•°:
            error: LLMå®¢æˆ·ç«¯æŠ›å‡ºçš„å¼‚å¸¸å¯¹è±¡ã€‚

        è¿”å›:
            bool: è‹¥åŒ¹é…åˆ°å†…å®¹å®¡æŸ¥å…³é”®è¯åˆ™è¿”å›Trueï¼Œå¦åˆ™ä¸ºFalseã€‚
        """
        message = str(error) if error else ""
        if not message:
            return False
        normalized = message.lower()
        keywords = [
            "inappropriate content",
            "content violation",
            "content moderation",
            "model-studio/error-code",
        ]
        return any(keyword in normalized for keyword in keywords)

    def _run_stage_with_retry(
        self,
        stage_name: str,
        fn: Callable[[], Any],
        expected_keys: Optional[List[str]] = None,
        postprocess: Optional[Callable[[Dict[str, Any], str], Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå•ä¸ªLLMé˜¶æ®µå¹¶åœ¨ç»“æ„å¼‚å¸¸æ—¶æœ‰é™æ¬¡é‡è¯•ã€‚

        è¯¥æ–¹æ³•åªé’ˆå¯¹ç»“æ„ç±»é”™è¯¯åšæœ¬åœ°ä¿®å¤/é‡è¯•ï¼Œé¿å…æ•´ä¸ªAgenté‡å¯ã€‚
        """
        last_error: Optional[Exception] = None
        for attempt in range(1, self._STRUCTURAL_RETRY_ATTEMPTS + 1):
            try:
                raw_result = fn()
                result = self._ensure_mapping(raw_result, stage_name, expected_keys)
                if postprocess:
                    result = postprocess(result, stage_name)
                return result
            except StageOutputFormatError as exc:
                last_error = exc
                logger.warning(
                    "{stage} è¾“å‡ºç»“æ„å¼‚å¸¸ï¼ˆç¬¬ {attempt}/{total} æ¬¡ï¼‰ï¼Œå°†å°è¯•ä¿®å¤æˆ–é‡è¯•: {error}",
                    stage=stage_name,
                    attempt=attempt,
                    total=self._STRUCTURAL_RETRY_ATTEMPTS,
                    error=exc,
                )
                if attempt >= self._STRUCTURAL_RETRY_ATTEMPTS:
                    break
        raise last_error  # type: ignore[misc]

    def _ensure_mapping(
        self,
        value: Any,
        context: str,
        expected_keys: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        ç¡®ä¿é˜¶æ®µè¾“å‡ºä¸ºdictï¼›è‹¥è¿”å›åˆ—è¡¨åˆ™å°è¯•æå–æœ€ä½³åŒ¹é…å…ƒç´ ã€‚
        """
        if isinstance(value, dict):
            return value

        if isinstance(value, list):
            candidates = [item for item in value if isinstance(item, dict)]
            if candidates:
                best = candidates[0]
                if expected_keys:
                    candidates.sort(
                        key=lambda item: sum(1 for key in expected_keys if key in item),
                        reverse=True,
                    )
                    best = candidates[0]
                logger.warning(
                    "{context} è¿”å›åˆ—è¡¨ï¼Œå·²è‡ªåŠ¨æå–åŒ…å«æœ€å¤šé¢„æœŸé”®çš„å…ƒç´ ç»§ç»­æ‰§è¡Œ",
                    context=context,
                )
                return best
            raise StageOutputFormatError(f"{context} è¿”å›åˆ—è¡¨ä½†ç¼ºå°‘å¯ç”¨çš„å¯¹è±¡å…ƒç´ ")

        if value is None:
            raise StageOutputFormatError(f"{context} è¿”å›ç©ºç»“æœ")

        raise StageOutputFormatError(
            f"{context} è¿”å›ç±»å‹ {type(value).__name__}ï¼ŒæœŸæœ›å­—å…¸"
        )

    def _normalize_word_plan(self, word_plan: Dict[str, Any], stage_name: str) -> Dict[str, Any]:
        """
        æ¸…æ´—ç¯‡å¹…è§„åˆ’ç»“æœï¼Œç¡®ä¿ chapters/globalGuidelines/totalWords ç±»å‹å®‰å…¨ã€‚
        """
        raw_chapters = word_plan.get("chapters", [])
        if isinstance(raw_chapters, dict):
            chapters_iterable = raw_chapters.values()
        elif isinstance(raw_chapters, list):
            chapters_iterable = raw_chapters
        else:
            chapters_iterable = []

        normalized: List[Dict[str, Any]] = []
        for idx, entry in enumerate(chapters_iterable):
            if isinstance(entry, dict):
                normalized.append(entry)
                continue
            if isinstance(entry, list):
                dict_candidate = next((item for item in entry if isinstance(item, dict)), None)
                if dict_candidate:
                    logger.warning(
                        "{stage} ç¬¬ {idx} ä¸ªç« èŠ‚æ¡ç›®ä¸ºåˆ—è¡¨ï¼Œå·²æå–é¦–ä¸ªå¯¹è±¡ç”¨äºåç»­æµç¨‹",
                        stage=stage_name,
                        idx=idx + 1,
                    )
                    normalized.append(dict_candidate)
                    continue
            logger.warning(
                "{stage} è·³è¿‡æ— æ³•è§£æçš„ç« èŠ‚æ¡ç›®#{idx}ï¼ˆç±»å‹: {type_name}ï¼‰",
                stage=stage_name,
                idx=idx + 1,
                type_name=type(entry).__name__,
            )

        if not normalized:
            raise StageOutputFormatError(f"{stage_name} ç¼ºå°‘æœ‰æ•ˆçš„ç« èŠ‚è§„åˆ’ï¼Œæ— æ³•ç»§ç»­")

        word_plan["chapters"] = normalized

        guidelines = word_plan.get("globalGuidelines")
        if not isinstance(guidelines, list):
            if guidelines is None or guidelines == "":
                word_plan["globalGuidelines"] = []
            else:
                logger.warning(
                    "{stage} globalGuidelines ç±»å‹å¼‚å¸¸ï¼Œå·²è½¬æ¢ä¸ºåˆ—è¡¨å°è£…",
                    stage=stage_name,
                )
                word_plan["globalGuidelines"] = [guidelines]

        if not isinstance(word_plan.get("totalWords"), (int, float)):
            logger.warning(
                "{stage} totalWords ç±»å‹å¼‚å¸¸ï¼Œä½¿ç”¨é»˜è®¤å€¼ 10000",
                stage=stage_name,
            )
            word_plan["totalWords"] = 10000

        return word_plan

    def _finalize_sparse_chapter(self, chapter: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ„é€ å†…å®¹ç¨€ç–å…œåº•ç« èŠ‚ï¼šå¤åˆ¶åŸå§‹payloadå¹¶æ’å…¥æ¸©é¦¨æç¤ºæ®µè½ã€‚
        """
        safe_chapter = deepcopy(chapter or {})
        if not isinstance(safe_chapter, dict):
            safe_chapter = {}
        self._ensure_sparse_warning_block(safe_chapter)
        return safe_chapter

    def _ensure_sparse_warning_block(self, chapter: Dict[str, Any]) -> None:
        """
        å°†æç¤ºæ®µè½æ’åœ¨ç« èŠ‚æ ‡é¢˜åï¼Œæé†’è¯»è€…è¯¥ç« å­—æ•°åå°‘ã€‚
        """
        warning_block = {
            "type": "paragraph",
            "inlines": [
                {
                    "text": self._CONTENT_SPARSE_WARNING_TEXT,
                    "marks": [{"type": "italic"}],
                }
            ],
            "meta": {"role": "content-sparse-warning"},
        }
        blocks = chapter.get("blocks")
        if isinstance(blocks, list) and blocks:
            inserted = False
            for idx, block in enumerate(blocks):
                if isinstance(block, dict) and block.get("type") == "heading":
                    blocks.insert(idx + 1, warning_block)
                    inserted = True
                    break
            if not inserted:
                blocks.insert(0, warning_block)
        else:
            chapter["blocks"] = [warning_block]
        meta = chapter.get("meta")
        if isinstance(meta, dict):
            meta["contentSparseWarning"] = True
        else:
            chapter["meta"] = {"contentSparseWarning": True}

    def _stringify(self, value: Any) -> str:
        """
        å®‰å…¨åœ°å°†å¯¹è±¡è½¬æˆå­—ç¬¦ä¸²ã€‚

        - dict/list ç»Ÿä¸€åºåˆ—åŒ–ä¸ºæ ¼å¼åŒ– JSONï¼Œä¾¿äºæç¤ºè¯æ¶ˆè´¹ï¼›
        - å…¶ä»–ç±»å‹èµ° `str()`ï¼ŒNone åˆ™è¿”å›ç©ºä¸²ï¼Œé¿å… None ä¼ æ’­ã€‚

        å‚æ•°:
            value: ä»»æ„Pythonå¯¹è±¡ã€‚

        è¿”å›:
            str: é€‚é…æç¤ºè¯/æ—¥å¿—çš„å­—ç¬¦ä¸²è¡¨ç°ã€‚
        """
        if value is None:
            return ""
        if isinstance(value, str):
            return value
        if isinstance(value, (dict, list)):
            try:
                return json.dumps(value, ensure_ascii=False, indent=2)
            except Exception:
                return str(value)
        return str(value)

    def _default_theme_tokens(self) -> Dict[str, Any]:
        """
        æ„é€ é»˜è®¤ä¸»é¢˜å˜é‡ï¼Œä¾›æ¸²æŸ“å™¨/LLMå…±ç”¨ã€‚

        å½“å¸ƒå±€èŠ‚ç‚¹æœªè¿”å›ä¸“å±é…è‰²æ—¶ä½¿ç”¨è¯¥å¥—è‰²æ¿ï¼Œä¿æŒæŠ¥å‘Šé£æ ¼ç»Ÿä¸€ã€‚

        è¿”å›:
            dict: åŒ…å«é¢œè‰²ã€å­—ä½“ã€é—´è·ã€å¸ƒå°”å¼€å…³ç­‰æ¸²æŸ“å‚æ•°çš„ä¸»é¢˜å­—å…¸ã€‚
        """
        return {
            "colors": {
                "bg": "#f8f9fa",
                "text": "#212529",
                "primary": "#007bff",
                "secondary": "#6c757d",
                "card": "#ffffff",
                "border": "#dee2e6",
                "accent1": "#17a2b8",
                "accent2": "#28a745",
                "accent3": "#ffc107",
                "accent4": "#dc3545",
            },
            "fonts": {
                "body": "-apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, 'Noto Sans', sans-serif",
                "heading": "'Source Han Sans SC', 'PingFang SC', 'Microsoft YaHei', sans-serif",
            },
            "spacing": {"container": "1200px", "gutter": "24px"},
            "vars": {
                "header_sticky": True,
                "toc_depth": 3,
                "enable_dark_mode": True,
            },
        }

    def _build_template_overview(
        self,
        template_markdown: str,
        sections: List[TemplateSection],
    ) -> Dict[str, Any]:
        """
        æå–æ¨¡æ¿æ ‡é¢˜ä¸ç« èŠ‚éª¨æ¶ï¼Œä¾›è®¾è®¡/ç¯‡å¹…è§„åˆ’ç»Ÿä¸€å¼•ç”¨ã€‚

        åŒæ—¶è®°å½•ç« èŠ‚ID/slug/orderç­‰è¾…åŠ©å­—æ®µï¼Œä¿è¯å¤šèŠ‚ç‚¹å¯¹é½ã€‚

        å‚æ•°:
            template_markdown: æ¨¡æ¿åŸæ–‡ï¼Œç”¨äºè§£æå…¨å±€æ ‡é¢˜ã€‚
            sections: `TemplateSection` åˆ—è¡¨ï¼Œä½œä¸ºç« èŠ‚éª¨æ¶ã€‚

        è¿”å›:
            dict: åŒ…å«æ¨¡æ¿æ ‡é¢˜ä¸ç« èŠ‚å…ƒæ•°æ®çš„æ¦‚è§ˆç»“æ„ã€‚
        """
        fallback_title = sections[0].title if sections else ""
        overview = {
            "title": self._extract_template_title(template_markdown, fallback_title),
            "chapters": [],
        }
        for section in sections:
            overview["chapters"].append(
                {
                    "chapterId": section.chapter_id,
                    "title": section.title,
                    "rawTitle": section.raw_title,
                    "number": section.number,
                    "slug": section.slug,
                    "order": section.order,
                    "depth": section.depth,
                    "outline": section.outline,
                }
            )
        return overview

    @staticmethod
    def _extract_template_title(template_markdown: str, fallback: str = "") -> str:
        """
        å°è¯•ä»Markdownä¸­æå–é¦–ä¸ªæ ‡é¢˜ã€‚

        ä¼˜å…ˆè¿”å›é¦–ä¸ª `#` è¯­æ³•æ ‡é¢˜ï¼›å¦‚æœæ¨¡æ¿é¦–è¡Œå°±æ˜¯æ­£æ–‡ï¼Œåˆ™å›é€€åˆ°
        ç¬¬ä¸€è¡Œéç©ºæ–‡æœ¬æˆ–è°ƒç”¨æ–¹æä¾›çš„ fallbackã€‚

        å‚æ•°:
            template_markdown: æ¨¡æ¿åŸæ–‡ã€‚
            fallback: å¤‡ç”¨æ ‡é¢˜ï¼Œå½“æ–‡æ¡£ç¼ºå°‘æ˜¾å¼æ ‡é¢˜æ—¶ä½¿ç”¨ã€‚

        è¿”å›:
            str: è§£æåˆ°çš„æ ‡é¢˜æ–‡æœ¬ã€‚
        """
        for line in template_markdown.splitlines():
            stripped = line.strip()
            if not stripped:
                continue
            if stripped.startswith("#"):
                return stripped.lstrip("#").strip()
            if stripped:
                fallback = fallback or stripped
        return fallback or "æ™ºèƒ½èˆ†æƒ…åˆ†ææŠ¥å‘Š"
    
    def _get_fallback_template_content(self) -> str:
        """
        è·å–å¤‡ç”¨æ¨¡æ¿å†…å®¹ã€‚

        å½“æ¨¡æ¿ç›®å½•ä¸å¯ç”¨æˆ–LLMé€‰æ‹©å¤±è´¥æ—¶ä½¿ç”¨è¯¥ Markdown æ¨¡æ¿ï¼Œ
        ä¿è¯åç»­æµç¨‹ä»èƒ½ç»™å‡ºç»“æ„åŒ–ç« èŠ‚ã€‚
        """
        return """# ç¤¾ä¼šå…¬å…±çƒ­ç‚¹äº‹ä»¶åˆ†ææŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
æœ¬æŠ¥å‘Šé’ˆå¯¹å½“å‰ç¤¾ä¼šçƒ­ç‚¹äº‹ä»¶è¿›è¡Œç»¼åˆåˆ†æï¼Œæ•´åˆäº†å¤šæ–¹ä¿¡æ¯æºçš„è§‚ç‚¹å’Œæ•°æ®ã€‚

## äº‹ä»¶æ¦‚å†µ
### åŸºæœ¬ä¿¡æ¯
- äº‹ä»¶æ€§è´¨ï¼š{event_nature}
- å‘ç”Ÿæ—¶é—´ï¼š{event_time}
- æ¶‰åŠèŒƒå›´ï¼š{event_scope}

## èˆ†æƒ…æ€åŠ¿åˆ†æ
### æ•´ä½“è¶‹åŠ¿
{sentiment_analysis}

### ä¸»è¦è§‚ç‚¹åˆ†å¸ƒ
{opinion_distribution}

## åª’ä½“æŠ¥é“åˆ†æ
### ä¸»æµåª’ä½“æ€åº¦
{media_analysis}

### æŠ¥é“é‡ç‚¹
{report_focus}

## ç¤¾ä¼šå½±å“è¯„ä¼°
### ç›´æ¥å½±å“
{direct_impact}

### æ½œåœ¨å½±å“
{potential_impact}

## åº”å¯¹å»ºè®®
### å³æ—¶æªæ–½
{immediate_actions}

### é•¿æœŸç­–ç•¥
{long_term_strategy}

## ç»“è®ºä¸å±•æœ›
{conclusion}

---
*æŠ¥å‘Šç±»å‹ï¼šç¤¾ä¼šå…¬å…±çƒ­ç‚¹äº‹ä»¶åˆ†æ*
*ç”Ÿæˆæ—¶é—´ï¼š{generation_time}*
"""
    
    def _save_report(self, html_content: str, document_ir: Dict[str, Any], report_id: str) -> Dict[str, Any]:
        """
        ä¿å­˜HTMLä¸IRåˆ°æ–‡ä»¶å¹¶è¿”å›è·¯å¾„ä¿¡æ¯ã€‚

        ç”ŸæˆåŸºäºæŸ¥è¯¢å’Œæ—¶é—´æˆ³çš„æ˜“è¯»æ–‡ä»¶åï¼ŒåŒæ—¶ä¹ŸæŠŠè¿è¡Œæ€çš„
        `ReportState` å†™å…¥ JSONï¼Œæ–¹ä¾¿ä¸‹æ¸¸æ’éšœæˆ–æ–­ç‚¹ç»­è·‘ã€‚

        å‚æ•°:
            html_content: æ¸²æŸ“åçš„HTMLæ­£æ–‡ã€‚
            document_ir: Document IRç»“æ„åŒ–æ•°æ®ã€‚
            report_id: å½“å‰ä»»åŠ¡IDï¼Œç”¨äºåˆ›å»ºç‹¬ç«‹æ–‡ä»¶åã€‚

        è¿”å›:
            dict: è®°å½•HTML/IR/Stateæ–‡ä»¶çš„ç»å¯¹ä¸ç›¸å¯¹è·¯å¾„ä¿¡æ¯ã€‚
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        query_safe = "".join(
            c for c in self.state.metadata.query if c.isalnum() or c in (" ", "-", "_")
        ).rstrip()
        query_safe = query_safe.replace(" ", "_")[:30] or "report"

        html_filename = f"final_report_{query_safe}_{timestamp}.html"
        html_path = Path(self.config.OUTPUT_DIR) / html_filename
        html_path.write_text(html_content, encoding="utf-8")
        html_abs = str(html_path.resolve())
        html_rel = os.path.relpath(html_abs, os.getcwd())

        ir_path = self._save_document_ir(document_ir, query_safe, timestamp)
        ir_abs = str(ir_path.resolve())
        ir_rel = os.path.relpath(ir_abs, os.getcwd())

        state_filename = f"report_state_{query_safe}_{timestamp}.json"
        state_path = Path(self.config.OUTPUT_DIR) / state_filename
        self.state.save_to_file(str(state_path))
        state_abs = str(state_path.resolve())
        state_rel = os.path.relpath(state_abs, os.getcwd())

        logger.info(f"HTMLæŠ¥å‘Šå·²ä¿å­˜: {html_path}")
        logger.info(f"Document IRå·²ä¿å­˜: {ir_path}")
        logger.info(f"çŠ¶æ€å·²ä¿å­˜åˆ°: {state_path}")
        
        return {
            'report_filename': html_filename,
            'report_filepath': html_abs,
            'report_relative_path': html_rel,
            'ir_filename': ir_path.name,
            'ir_filepath': ir_abs,
            'ir_relative_path': ir_rel,
            'state_filename': state_filename,
            'state_filepath': state_abs,
            'state_relative_path': state_rel,
        }

    def _save_document_ir(self, document_ir: Dict[str, Any], query_safe: str, timestamp: str) -> Path:
        """
        å°†æ•´æœ¬IRå†™å…¥ç‹¬ç«‹ç›®å½•ã€‚

        `Document IR` ä¸ HTML è§£è€¦ä¿å­˜ï¼Œä¾¿äºè°ƒè¯•æ¸²æŸ“å·®å¼‚ä»¥åŠ
        åœ¨ä¸é‡æ–°è·‘ LLM çš„æƒ…å†µä¸‹å†æ¬¡æ¸²æŸ“æˆ–å¯¼å‡ºå…¶ä»–æ ¼å¼ã€‚

        å‚æ•°:
            document_ir: æ•´æœ¬æŠ¥å‘Šçš„IRç»“æ„ã€‚
            query_safe: å·²æ¸…æ´—çš„æŸ¥è¯¢çŸ­è¯­ï¼Œç”¨äºæ–‡ä»¶å‘½åã€‚
            timestamp: è¿è¡Œæ—¶é—´æˆ³ï¼Œä¿è¯æ–‡ä»¶åå”¯ä¸€ã€‚

        è¿”å›:
            Path: æŒ‡å‘ä¿å­˜åçš„IRæ–‡ä»¶è·¯å¾„ã€‚
        """
        filename = f"report_ir_{query_safe}_{timestamp}.json"
        ir_path = Path(self.config.DOCUMENT_IR_OUTPUT_DIR) / filename
        ir_path.write_text(
            json.dumps(document_ir, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        return ir_path
    
    def _persist_planning_artifacts(
        self,
        run_dir: Path,
        layout_design: Dict[str, Any],
        word_plan: Dict[str, Any],
        template_overview: Dict[str, Any],
    ):
        """
        å°†æ–‡æ¡£è®¾è®¡ç¨¿ã€ç¯‡å¹…è§„åˆ’ä¸æ¨¡æ¿æ¦‚è§ˆå¦å­˜æˆJSONã€‚

        è¿™äº›ä¸­é—´ä»¶æ–‡ä»¶ï¼ˆdocument_layout/word_plan/template_overviewï¼‰
        æ–¹ä¾¿åœ¨è°ƒè¯•æˆ–å¤ç›˜æ—¶å¿«é€Ÿå®šä½ï¼šæ ‡é¢˜/ç›®å½•/ä¸»é¢˜æ˜¯å¦‚ä½•ç¡®å®šçš„ã€
        å­—æ•°åˆ†é…æœ‰ä»€ä¹ˆè¦æ±‚ï¼Œä»¥ä¾¿åç»­äººå·¥æ ¡æ­£ã€‚

        å‚æ•°:
            run_dir: ç« èŠ‚è¾“å‡ºæ ¹ç›®å½•ã€‚
            layout_design: æ–‡æ¡£å¸ƒå±€èŠ‚ç‚¹çš„åŸå§‹è¾“å‡ºã€‚
            word_plan: ç¯‡å¹…è§„åˆ’èŠ‚ç‚¹è¾“å‡ºã€‚
            template_overview: æ¨¡æ¿æ¦‚è§ˆJSONã€‚
        """
        artifacts = {
            "document_layout": layout_design,
            "word_plan": word_plan,
            "template_overview": template_overview,
        }
        for name, payload in artifacts.items():
            if not payload:
                continue
            path = run_dir / f"{name}.json"
            try:
                path.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
            except Exception as exc:
                logger.warning(f"å†™å…¥{name}å¤±è´¥: {exc}")
    
    def get_progress_summary(self) -> Dict[str, Any]:
        """è·å–è¿›åº¦æ‘˜è¦ï¼Œç›´æ¥è¿”å›å¯åºåˆ—åŒ–çš„çŠ¶æ€å­—å…¸ä¾›APIå±‚æŸ¥è¯¢ã€‚"""
        return self.state.to_dict()
    
    def load_state(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½çŠ¶æ€å¹¶è¦†ç›–å½“å‰stateï¼Œä¾¿äºæ–­ç‚¹æ¢å¤ã€‚"""
        self.state = ReportState.load_from_file(filepath)
        logger.info(f"çŠ¶æ€å·²ä» {filepath} åŠ è½½")
    
    def save_state(self, filepath: str):
        """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶ï¼Œé€šå¸¸ç”¨äºä»»åŠ¡å®Œæˆåçš„åˆ†æä¸å¤‡ä»½ã€‚"""
        self.state.save_to_file(filepath)
        logger.info(f"çŠ¶æ€å·²ä¿å­˜åˆ° {filepath}")
    
    def check_input_files(self, insight_dir: str, media_dir: str, query_dir: str, forum_log_path: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å‡†å¤‡å°±ç»ªï¼ˆåŸºäºæ–‡ä»¶æ•°é‡å¢åŠ ï¼‰ã€‚
        
        Args:
            insight_dir: InsightEngineæŠ¥å‘Šç›®å½•
            media_dir: MediaEngineæŠ¥å‘Šç›®å½•
            query_dir: QueryEngineæŠ¥å‘Šç›®å½•
            forum_log_path: è®ºå›æ—¥å¿—æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸ï¼ŒåŒ…å«æ–‡ä»¶è®¡æ•°ã€ç¼ºå¤±åˆ—è¡¨ã€æœ€æ–°æ–‡ä»¶è·¯å¾„ç­‰
        """
        # æ£€æŸ¥å„ä¸ªæŠ¥å‘Šç›®å½•çš„æ–‡ä»¶æ•°é‡å˜åŒ–
        directories = {
            'insight': insight_dir,
            'media': media_dir,
            'query': query_dir
        }
        
        # ä½¿ç”¨æ–‡ä»¶åŸºå‡†ç®¡ç†å™¨æ£€æŸ¥æ–°æ–‡ä»¶
        check_result = self.file_baseline.check_new_files(directories)
        
        # æ£€æŸ¥è®ºå›æ—¥å¿—
        forum_ready = os.path.exists(forum_log_path)
        
        # æ„å»ºè¿”å›ç»“æœ
        result = {
            'ready': check_result['ready'] and forum_ready,
            'baseline_counts': check_result['baseline_counts'],
            'current_counts': check_result['current_counts'],
            'new_files_found': check_result['new_files_found'],
            'missing_files': [],
            'files_found': [],
            'latest_files': {}
        }
        
        # æ„å»ºè¯¦ç»†ä¿¡æ¯
        for engine, new_count in check_result['new_files_found'].items():
            current_count = check_result['current_counts'][engine]
            baseline_count = check_result['baseline_counts'].get(engine, 0)
            
            if new_count > 0:
                result['files_found'].append(f"{engine}: {current_count}ä¸ªæ–‡ä»¶ (æ–°å¢{new_count}ä¸ª)")
            else:
                result['missing_files'].append(f"{engine}: {current_count}ä¸ªæ–‡ä»¶ (åŸºå‡†{baseline_count}ä¸ªï¼Œæ— æ–°å¢)")
        
        # æ£€æŸ¥è®ºå›æ—¥å¿—
        if forum_ready:
            result['files_found'].append(f"forum: {os.path.basename(forum_log_path)}")
        else:
            result['missing_files'].append("forum: æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨")
        
        # è·å–æœ€æ–°æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå®é™…æŠ¥å‘Šç”Ÿæˆï¼‰
        if result['ready']:
            result['latest_files'] = self.file_baseline.get_latest_files(directories)
            if forum_ready:
                result['latest_files']['forum'] = forum_log_path
        
        return result
    
    def load_input_files(self, file_paths: Dict[str, str]) -> Dict[str, Any]:
        """
        åŠ è½½è¾“å…¥æ–‡ä»¶å†…å®¹
        
        Args:
            file_paths: æ–‡ä»¶è·¯å¾„å­—å…¸
            
        Returns:
            åŠ è½½çš„å†…å®¹å­—å…¸ï¼ŒåŒ…å« `reports` åˆ—è¡¨ä¸ `forum_logs` å­—ç¬¦ä¸²
        """
        content = {
            'reports': [],
            'forum_logs': ''
        }
        
        # åŠ è½½æŠ¥å‘Šæ–‡ä»¶
        engines = ['query', 'media', 'insight']
        for engine in engines:
            if engine in file_paths:
                try:
                    with open(file_paths[engine], 'r', encoding='utf-8') as f:
                        report_content = f.read()
                    content['reports'].append(report_content)
                    logger.info(f"å·²åŠ è½½ {engine} æŠ¥å‘Š: {len(report_content)} å­—ç¬¦")
                except Exception as e:
                    logger.exception(f"åŠ è½½ {engine} æŠ¥å‘Šå¤±è´¥: {str(e)}")
                    content['reports'].append("")
        
        # åŠ è½½è®ºå›æ—¥å¿—
        if 'forum' in file_paths:
            try:
                with open(file_paths['forum'], 'r', encoding='utf-8') as f:
                    content['forum_logs'] = f.read()
                logger.info(f"å·²åŠ è½½è®ºå›æ—¥å¿—: {len(content['forum_logs'])} å­—ç¬¦")
            except Exception as e:
                logger.exception(f"åŠ è½½è®ºå›æ—¥å¿—å¤±è´¥: {str(e)}")
        
        return content


def create_agent(config_file: Optional[str] = None) -> ReportAgent:
    """
    åˆ›å»ºReport Agentå®ä¾‹çš„ä¾¿æ·å‡½æ•°ã€‚
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        ReportAgentå®ä¾‹

    ç›®å‰ä»¥ç¯å¢ƒå˜é‡é©±åŠ¨ `Settings`ï¼Œä¿ç•™ `config_file` å‚æ•°ä¾¿äºæœªæ¥æ‰©å±•ã€‚
    """
    
    config = Settings() # ä»¥ç©ºé…ç½®åˆå§‹åŒ–ï¼Œè€Œä»ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–
    return ReportAgent(config)
